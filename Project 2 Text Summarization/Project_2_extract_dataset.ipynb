{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1MKnTx6J9EkVdN_dQVfvfcNPrtPvn7EdI",
      "authorship_tag": "ABX9TyOxzaJvJ0bIJjnZp7QCGKLQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kairamilanifitria/NLP-Projects/blob/main/Project%202%20Text%20Summarization/Project_2_extract_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import os\n",
        "\n",
        "# Replace with your tar.gz file path\n",
        "tar_gz_file_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6_data.tar.gz'\n",
        "\n",
        "# Replace with your desired extraction directory in Google Drive\n",
        "extracted_folder_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "if not os.path.exists(extracted_folder_path):\n",
        "    os.makedirs(extracted_folder_path)\n",
        "\n",
        "# Extract the tar.gz file\n",
        "with tarfile.open(tar_gz_file_path, 'r:gz') as tar:\n",
        "    tar.extractall(path=extracted_folder_path)\n",
        "\n",
        "print(f\"File extracted to: {extracted_folder_path}\")\n"
      ],
      "metadata": {
        "id": "s_grJ5U6Jodm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406a59d2-754e-4abe-dc33-00f0a034891f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File extracted to: /content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracted Dataset :\n",
        "https://drive.google.com/drive/folders/1eGh-hY1pD8nLCAU9gWIAJXeSm5PaOCaI?usp=sharing"
      ],
      "metadata": {
        "id": "tdEsbChSsAgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/train'\n",
        "\n",
        "total_files = 0\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "  total_files += len(files)\n",
        "\n",
        "print(f\"Total files in {folder_path}: {total_files}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loXgaPYAq3GG",
        "outputId": "1a255c98-f501-406f-f5dd-da7ec9cede89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files in /content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/train: 193883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/train'\n",
        "csv_file_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/train.csv'\n",
        "\n",
        "data_list = []\n",
        "for filename in os.listdir(folder_path):\n",
        "  if filename.endswith('.json'):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    with open(file_path, 'r') as f:\n",
        "      try:\n",
        "        data = json.load(f)\n",
        "        data_list.append(data)\n",
        "      except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON in file: {filename}, Error: {e}\")\n",
        "\n",
        "\n",
        "df = pd.json_normalize(data_list)\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"CSV file created at: {csv_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wMGf6lde0Nd",
        "outputId": "73799e10-2904-4dee-ae37-aa5ee29e89c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created at: /content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/test'\n",
        "csv_file_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/test.csv'\n",
        "\n",
        "data_list = []\n",
        "for filename in os.listdir(folder_path):\n",
        "  if filename.endswith('.json'):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    with open(file_path, 'r') as f:\n",
        "      try:\n",
        "        data = json.load(f)\n",
        "        data_list.append(data)\n",
        "      except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON in file: {filename}, Error: {e}\")\n",
        "\n",
        "\n",
        "df = pd.json_normalize(data_list)\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"CSV file created at: {csv_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS3uvWGetD54",
        "outputId": "cc03e0da-8600-4c97-f83b-1447988594d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created at: /content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/dev'\n",
        "csv_file_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/dev.csv'\n",
        "\n",
        "data_list = []\n",
        "for filename in os.listdir(folder_path):\n",
        "  if filename.endswith('.json'):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    with open(file_path, 'r') as f:\n",
        "      try:\n",
        "        data = json.load(f)\n",
        "        data_list.append(data)\n",
        "      except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON in file: {filename}, Error: {e}\")\n",
        "\n",
        "\n",
        "df = pd.json_normalize(data_list)\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"CSV file created at: {csv_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQCeTn_5yKhI",
        "outputId": "b05637f3-fb9a-4b17-926a-f5c0dc82eeab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created at: /content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/dev.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_file_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/train.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "print(df.loc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngbI343FyQxG",
        "outputId": "e664ddea-5b22-4c00-fb7c-b9763b83821c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                                                               238168\n",
            "url                   https://www.liputan6.com/news/read/238168/hayk...\n",
            "clean_article         [['Liputan6', '.', 'com', ',', 'Jakarta', ':',...\n",
            "clean_summary         [['Artis', 'muda', 'Haykal', 'dan', 'Putri', '...\n",
            "extractive_summary                                               [0, 4]\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_file_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/test.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "print(df.loc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "731mEXGqzHGa",
        "outputId": "600a6411-4a3d-412a-aa62-c66e4ae0c57c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                                                                22405\n",
            "url                   https://www.liputan6.com/news/read/22405/tommy...\n",
            "clean_article         [['Liputan6', '.', 'com', ',', 'Jakarta', ':',...\n",
            "clean_summary         [['Tommy', 'Soeharto', 'kembali', 'dicekal', '...\n",
            "extractive_summary                                               [1, 4]\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_file_path = '/content/drive/MyDrive/Bootcamp AI/Dataset/Task2 : Text Summarization/liputan6/liputan6_data/canonical/dev.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "print(df.loc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kYzqVSh0wi9",
        "outputId": "7b48efcc-478d-4f59-f9f4-b788455c15f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                                                                10362\n",
            "url                   https://www.liputan6.com/news/read/10362/masya...\n",
            "clean_article         [['Liputan6', '.', 'com', ',', 'Jakarta', ':',...\n",
            "clean_summary         [['Sejumlah', 'tokoh', 'masyarakat', 'Riau', '...\n",
            "extractive_summary                                               [0, 2]\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QjtaITcn0zYz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}